{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble as en\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wikipedia\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__File containing Athlete names__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fopen = open(\"C:\\\\Users\\\\padhu\\\\Documents\\\\Spring 2016\\\\MSA 8150 Machine Learning\\\\Final project\\\\Cleaned files\\\\names1.csv\",mode='r')\n",
    "names_list = fopen.readlines()\n",
    "names_list = [item.strip('\\n') for item in names_list]\n",
    "names_list = list(set(names_list))\n",
    "\n",
    "name_gender = {}\n",
    "name_age= {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Determining Gender from wikipedia page__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_words = [' his ',' him ',' he ']\n",
    "female_words = [' her ',' she ']\n",
    "\n",
    "def getGender(name):\n",
    "    try:\n",
    "        t= wikipedia.page(name)\n",
    "        summary = t.summary\n",
    "        summary = summary.replace(\"\\n\",\" \")\n",
    "        summary = summary.lower()\n",
    "        if ( (summary.find(female_words[0]) >0 or summary.find(female_words[1]) >0) and (summary.find(male_words[0]) >0 or  summary.find(male_words[1]) >0 or summary.find(male_words[2])>0)):\n",
    "            return \"found both\"\n",
    "        elif (summary.find(female_words[0]) >0 or summary.find(female_words[1]) >0):\n",
    "            return \"female\"\n",
    "        elif (summary.find(male_words[0]) >0 or  summary.find(male_words[1]) >0 or summary.find(male_words[2])>0):\n",
    "            return \"male\"\n",
    "        else:\n",
    "            return \"gender not found\"\n",
    "        \n",
    "    except:\n",
    "        return \"gender not found\"\n",
    "    \n",
    "for i in range(len(names_list)):\n",
    "    name_gender[names_list[i]] = getGender(names_list[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extract Year of birth from Wikipedia page__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yob = {}\n",
    "for i in range(len(names_list)):\n",
    "    try:\n",
    "        t= wikipedia.page(names_list[i])\n",
    "        summary = t.summary\n",
    "        summary = summary.lower()\n",
    "        summary = summary.replace(\"\\n\",\"\") \n",
    "        yob[names_list[i]] = re.search('\\((.*?)\\)',summary).group(1)\n",
    "        \n",
    "    except:\n",
    "        yob[names_list[i]] = \"yob not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input Data and Preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(\"C:\\\\Users\\\\padhu\\\\Documents\\\\Spring 2016\\\\MSA 8150 Machine Learning\\\\Final project\\\\datafile.csv\",index_col = None)\n",
    "df1 = df.drop(['Age','Name','Country'],axis=1)\n",
    "#df1\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for item in list(df1.columns):\n",
    "    temp = le.fit(list(df1[item]))\n",
    "    t = le.transform(list(df1[item]))\n",
    "    df1[item] = le.transform(list(df1[item]))\n",
    "\n",
    "df_test = df1.sample(30)\n",
    "\n",
    "X= df1.drop('Doping Indicator',axis=1)\n",
    "y = df1['Doping Indicator']\n",
    "#df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split the data for Training and Testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "df_train = pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Naive Bayes model- Training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Naive Bayes- Prediction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Gender', u'Sport', u'Medal', u'Age_group', u'Country_Medal_group'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_proba(X_test)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Decison Tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=80 does not match number of samples=7008",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-b22dc4bf3b58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\padhu\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[1;32m--> 240\u001b[1;33m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"min_samples_split must be greater than zero.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=80 does not match number of samples=7008"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "cols = df1.columns\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydot \n",
    "from IPython.display import Image  \n",
    "\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file=dot_data,\n",
    "    feature_names=cols,filled=True) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_pdf(\"doping.pdf\") \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Balanced Random Forest sampling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2313"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 21\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 14\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 15\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 14\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 15\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 21\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 21\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 21\n",
      "actual: 15 predicted: 14\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 21\n",
      "actual: 15 predicted: 22\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 15\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 15\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 15\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 15\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 20\n",
      "actual: 15 predicted: 19\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 17\n",
      "actual: 15 predicted: 16\n",
      "actual: 15 predicted: 18\n",
      "actual: 15 predicted: 22\n",
      "actual: 15 predicted: 17\n"
     ]
    }
   ],
   "source": [
    "minor_class_df = df_train[df_train['Doping Indicator'] == 1]\n",
    "major_class_df = df_train[df_train['Doping Indicator'] == 0]\n",
    "\n",
    "t = pd.concat([major_class_df.sample(15),minor_class_df.sample(15)])\n",
    "#t= minor_class_df[:5]\n",
    "xt = t.drop('Doping Indicator',axis=1)\n",
    "yt = t['Doping Indicator']\n",
    "\n",
    "#xt = X_test\n",
    "#yt = y_test\n",
    "\n",
    "scores = []\n",
    "scores_list={}\n",
    "predict = []\n",
    "\n",
    "for i in range(100):\n",
    "    temp_df = pd.concat([major_class_df.sample(40),minor_class_df.sample(40)])\n",
    "    x = temp_df.drop('Doping Indicator',axis=1)\n",
    "    y = temp_df['Doping Indicator']\n",
    "    mod = en.RandomForestClassifier(n_estimators=10, oob_score = True)\n",
    "    mod.fit(x,y)\n",
    "    print \"actual:\", sum(yt),\"predicted:\",sum(mod.predict(xt))\n",
    "    predict.append(mod.predict(xt))\n",
    "    score = cross_validation.cross_val_score(mod,x,y,cv=10)\n",
    "    #print sum(score)/len(score)\n",
    "    scores.append(sum(score)/len(score))\n",
    "    scores_list[i]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_count = [sum(item) for item in predict]\n",
    "#predict_count\n",
    "scores\n",
    "type(scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'index', u'Gender', u'Sport', u'Medal', u'Age_group',\n",
       "       u'Country_Medal_group', u'Doping Indicator', u'predicted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amanda = pd.concat([X_test,y_test],axis=1)\n",
    "Amanda.reset_index(inplace=True)\n",
    "Myanka = pd.DataFrame(predict[5],columns = ['predicted'])\n",
    "\n",
    "\n",
    "final = pd.concat([Amanda,Myanka],axis=1)\n",
    "\n",
    "#df_train\n",
    "#pd.concat([X_test,y_test],axis=1)\n",
    "#pd.DataFrame(predict[5],index= None)\n",
    "\n",
    "\n",
    "final\n",
    "\n",
    "final.columns\n",
    "\n",
    "cols = ['Gender', 'Sport', 'Medal', 'Age_group','Country_Medal_group']\n",
    "\n",
    "for item in cols:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
